{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pdb\n",
    "import time\n",
    "import os\n",
    "from tree_utils import flatten_scores, flatten_indices\n",
    "import sys\n",
    "from utils import *\n",
    "import open3d as o3d\n",
    "from open3d import JVisualizer\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inds):\n",
    "    return np.mean(objectness_objects[inds]).item()\n",
    "    \n",
    "    \n",
    "def segment(id_, eps_list, cloud, original_indices=None, aggr_func='min'):\n",
    "    if not all(eps_list[i] > eps_list[i+1] for i in range(len(eps_list)-1)):\n",
    "        raise ValueError('eps_list is not sorted in descending order')\n",
    "    # pick the first threshold from the list\n",
    "    max_eps = eps_list[0]\n",
    "    #\n",
    "    if original_indices is None: original_indices = np.arange(cloud.shape[0])\n",
    "    if isinstance(original_indices, list): original_indices = np.array(original_indices)\n",
    "    # spatial segmentation\n",
    "    dbscan = DBSCAN(max_eps, min_samples=1).fit(cloud[original_indices,:])\n",
    "    labels = dbscan.labels_\n",
    "    # evaluate every segment\n",
    "    indices, scores = [], []\n",
    "    for unique_label in np.unique(labels):\n",
    "        inds = original_indices[np.flatnonzero(labels == unique_label)]\n",
    "        indices.append(inds.tolist())\n",
    "        scores.append(evaluate(inds))\n",
    "    # return if we are done\n",
    "    if len(eps_list) == 1: return indices, scores\n",
    "    # expand recursively\n",
    "    final_indices, final_scores = [], []\n",
    "    for i, (inds, score) in enumerate(zip(indices, scores)):\n",
    "        # focus on this segment\n",
    "        fine_indices, fine_scores = segment(id_, eps_list[1:], cloud, inds)\n",
    "        # flatten scores to get the minimum (keep structure)\n",
    "        flat_fine_scores = flatten_scores(fine_scores)\n",
    "        if aggr_func == 'min':\n",
    "            aggr_score = np.min(flat_fine_scores)\n",
    "        elif aggr_func == 'avg':\n",
    "            aggr_score = np.mean(flat_fine_scores)\n",
    "        elif aggr_func == 'sum':\n",
    "            aggr_score = np.sum(flat_fine_scores)\n",
    "        elif aggr_func == 'wavg':\n",
    "            # compute a weighted average (each score is weighted by the number of points)\n",
    "            flat_fine_indices = flatten_indices(fine_indices)\n",
    "            sum_count, sum_score = 0, 0.0\n",
    "            for indices, score in zip(flat_fine_indices, flat_fine_scores):\n",
    "                sum_count += len(indices)\n",
    "                sum_score += len(indices)*score\n",
    "            aggr_score = float(sum_score)/sum_count\n",
    "        elif aggr_func == 'd2wavg':\n",
    "            # compute a weighted average (each score is weighted by the number of points)\n",
    "            flat_fine_indices = flatten_indices(fine_indices)\n",
    "            sum_count, sum_score = 0, 0.0\n",
    "            for indices, score in zip(flat_fine_indices, flat_fine_scores):\n",
    "                squared_dists = np.sum(cloud[inds,:]**2, axis=1)\n",
    "                sum_count += np.sum(squared_dists)\n",
    "                sum_score += np.sum(squared_dists * score)\n",
    "            aggr_score = float(sum_score)/sum_count\n",
    "\n",
    "        # COMMENTING THIS OUT BECAUSE OF ADDING SUM AS AN AGGR FUNC\n",
    "        # assert(aggr_score <= 1 and aggr_score >= 0)\n",
    "\n",
    "        # if splitting is better\n",
    "        if score < aggr_score:\n",
    "            final_indices.append(fine_indices)\n",
    "            final_scores.append(fine_scores)\n",
    "        else: # otherwise\n",
    "            final_indices.append(inds)\n",
    "            final_scores.append(score)\n",
    "    return final_indices, final_scores\n",
    "\n",
    "\n",
    "def vis_instance_o3d():\n",
    "    # visualization\n",
    "    pcd_objects = o3d.geometry.PointCloud()\n",
    "    colors = np.zeros((len(pts_velo_cs_objects), 4))\n",
    "    max_instance = len(flat_indices)\n",
    "    print(f\"point cloud has {max_instance + 1} clusters\")\n",
    "    colors_instance = plt.get_cmap(\"tab20\")(np.arange(len(flat_indices)) / (max_instance if max_instance > 0 else 1))\n",
    "\n",
    "    for idx in range(len(flat_indices)):\n",
    "        colors[flat_indices[idx]] = colors_instance[idx]\n",
    "\n",
    "    pcd_objects.points = o3d.utility.Vector3dVector(pts_velo_cs_objects[:, :3])\n",
    "    pcd_objects.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "\n",
    "    pcd_background = o3d.geometry.PointCloud()\n",
    "    pcd_background.points = o3d.utility.Vector3dVector(pts_velo_cs[background_mask, :3])\n",
    "    pcd_background.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "\n",
    "#     o3d.visualization.draw_geometries([pcd_objects, pcd_background])\n",
    "    visualizer = JVisualizer()\n",
    "    visualizer.add_geometry(pcd_objects) # Ani: adds the colourful points (each color is a new segmented instance)\n",
    "    visualizer.add_geometry(pcd_background) # Ani: adds the gray bg points (technically, these are not bg but actually known classes)\n",
    "    visualizer.show()\n",
    "\n",
    "    \n",
    "def vis_4dpls():\n",
    "    fg = o3d.geometry.PointCloud()\n",
    "    colors = np.zeros((len(pts_velo_cs_objects), 4))\n",
    "    max_cls = unk_label + 1 # [0, 11] for TS1\n",
    "    colors_cls = plt.get_cmap(\"tab20\")(np.arange(max_cls) / (max_cls if max_cls > 0 else 1))\n",
    "\n",
    "    colors = colors_cls[labels_objects]\n",
    "\n",
    "    visualizer = JVisualizer()\n",
    "    fg.points = o3d.utility.Vector3dVector(pts_velo_cs_objects[:, :3])\n",
    "    fg.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "    visualizer.add_geometry(fg)\n",
    "\n",
    "    bg = o3d.geometry.PointCloud()\n",
    "    bg.points = o3d.utility.Vector3dVector(pts_velo_cs[background_mask, :3])\n",
    "    bg.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "    visualizer.add_geometry(bg)\n",
    "    visualizer.show()\n",
    "\n",
    "\n",
    "def load_config(file, task_set):\n",
    "    with open(file, 'r') as stream:\n",
    "        doc = yaml.safe_load(stream)\n",
    "#         all_labels = doc['task_set_map'][task_set]['labels']\n",
    "#         learning_map_inv = doc['task_set_map'][task_set]['learning_map_inv']\n",
    "        learning_map = doc['task_set_map'][task_set]['learning_map']\n",
    "    learning_map_arr = np.zeros((np.max([k for k in learning_map.keys()]) + 1), dtype=np.int32)\n",
    "    for k, v in learning_map.items():\n",
    "        learning_map_arr[k] = v\n",
    "    return learning_map_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4071 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point cloud has 66 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ba7ba4fc264cb2a2cf9ebb8b045cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 2 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4071 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "seq = '08'\n",
    "# seq_prefix = '08_0'\n",
    "\n",
    "config_file = '/project_data/ramanan/achakrav/4D-PLS/data/SemanticKitti/semantic-kitti.yaml'\n",
    "\n",
    "task_set = 1\n",
    "# write_dir = '/project_data/ramanan/achakrav/hu-segmentation/kitti_raw_ts1_segmented/'\n",
    "write_dir = '/project_data/ramanan/achakrav/hu-segmentation/ts{}_trial/'.format(task_set)\n",
    "if not os.path.exists(write_dir):\n",
    "    os.makedirs(write_dir)\n",
    "\n",
    "# scan_folder = '/media/data/dataset/kitti-odometry/dataset/sequences/' + seq + '/velodyne'\n",
    "scan_folder = '/project_data/ramanan/achakrav/4D-PLS/data/SemanticKitti/sequences/' + seq + '/velodyne/'\n",
    "scan_files = load_paths(scan_folder)\n",
    "\n",
    "# objectness_folder = '/media/data/tmp/testsetobj'\n",
    "# objectness_files_raw = load_paths(objectness_folder)\n",
    "# objectness_files = [path for path in objectness_files_raw if seq_prefix in path]\n",
    "\n",
    "# semantic_folder = '/media/data/tmp/testsetsem'\n",
    "# semantic_files_raw = load_paths(semantic_folder)\n",
    "# semantic_files = [path for path in semantic_files_raw if seq_prefix in path]\n",
    "\n",
    "# objsem_folder = 'xieyuanlichen/tmp/seq08objsem'\n",
    "objsem_folder = '/project_data/ramanan/achakrav/4D-PLS/val_preds_TS{}/val_preds/'.format(task_set)\n",
    "objsem_files = load_paths(objsem_folder)\n",
    "\n",
    "label_folder = '/project_data/ramanan/achakrav/4D-PLS/data/SemanticKitti/sequences/' + seq + '/labels/'\n",
    "label_files = load_paths(label_folder)\n",
    "label_files = [x for x in label_files if '.label' in x]\n",
    "\n",
    "# for task set 1\n",
    "if task_set == 1:\n",
    "    class_strings = [\"car\", \"truck\", \"person\", \"road\", \"sidewalk\", \"building\", \"fence\", \"vegetation\", \"terrain\", \"pole\", \"unknown\"]\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "sem_file_mask = []\n",
    "obj_file_mask = []\n",
    "for idx, file in enumerate(objsem_files):\n",
    "    if '_c' in file:\n",
    "        obj_file_mask.append(idx)\n",
    "    elif '_u' not in file and '_i' not in file and '_e' not in file and '_pots' not in file:\n",
    "        sem_file_mask.append(idx)\n",
    "\n",
    "objectness_files = objsem_files[obj_file_mask]\n",
    "semantic_files = objsem_files[sem_file_mask]\n",
    "\n",
    "# for scan_file in scan_files:\n",
    "#     base_file = os.path.basename(scan_file)\n",
    "#     idx_num = base_file.split('.')[0]\n",
    "#     sem_file = '08_0{}.npy'.format(idx_num)\n",
    "#     sem_file = os.path.join(objsem_folder, sem_file)\n",
    "#     if sem_file not in objsem_files:\n",
    "#         pdb.set_trace()\n",
    "\n",
    "\n",
    "assert (len(semantic_files) == len(objectness_files))\n",
    "assert (len(semantic_files) == len(scan_files))\n",
    "\n",
    "learning_map = load_config(config_file, task_set)\n",
    "\n",
    "for idx in tqdm(range(len(objectness_files))):\n",
    "    # load scan\n",
    "    # frame_idx = int(os.path.basename(semantic_files[idx]).replace('.npy', '').replace('08_', ''))\n",
    "    # scan_file = scan_files[frame_idx]\n",
    "    scan_file = scan_files[idx]\n",
    "    pts_velo_cs = load_vertex(scan_file)\n",
    "    pts_indexes = np.arange(len(pts_velo_cs))\n",
    "\n",
    "    # load objectness\n",
    "    objectness_file = objectness_files[idx]\n",
    "    objectness = np.load(objectness_file)\n",
    "\n",
    "    # labels\n",
    "    label_file = semantic_files[idx]\n",
    "    labels = np.load(label_file)\n",
    "\n",
    "    unk_label = 11 # for task set 1\n",
    "\n",
    "    # ==========================================================================================\n",
    "    # Ani: plot predictions from 4DPLS \n",
    "    # ==========================================================================================\n",
    "    mask = labels != unk_label # Note: opposite to other plot since we plot known classes only\n",
    "    background_mask = labels == unk_label\n",
    "    \n",
    "    pts_velo_cs_objects = pts_velo_cs[mask]\n",
    "    objectness_objects = objectness[mask]\n",
    "    pts_indexes_objects = pts_indexes[mask]\n",
    "    labels_objects = labels[mask]\n",
    "\n",
    "    # visualize predictions\n",
    "#     vis_4dpls()\n",
    "#     break\n",
    "    # ==========================================================================================\n",
    "\n",
    "\n",
    "    # ==========================================================================================\n",
    "    # Ani: plot GT\n",
    "    # ==========================================================================================\n",
    "    gt_label_file = label_files[idx]\n",
    "    gt_label = np.fromfile(gt_label_file, dtype=np.int32)\n",
    "    gt_label = gt_label & 0xFFFF\n",
    "    gt_label = learning_map[gt_label]\n",
    "    \n",
    "    # to plot clustering segmentation output\n",
    "    mask = gt_label != unk_label\n",
    "    background_mask = gt_label == unk_label\n",
    "\n",
    "    pts_velo_cs_objects = pts_velo_cs[mask]\n",
    "    objectness_objects = objectness[mask]\n",
    "    pts_indexes_objects = pts_indexes[mask]\n",
    "    labels_objects = gt_label[mask]\n",
    "    \n",
    "    # visualize GT\n",
    "#     vis_4dpls()\n",
    "#     break\n",
    "    # ==========================================================================================\n",
    "    mask = labels == unk_label\n",
    "    background_mask = labels != unk_label\n",
    "    \n",
    "    pts_velo_cs_objects = pts_velo_cs[mask]\n",
    "    objectness_objects = objectness[mask]\n",
    "    pts_indexes_objects = pts_indexes[mask]\n",
    "    labels_objects = labels[mask]\n",
    "\n",
    "\n",
    "    # debug = o3d.geometry.PointCloud()\n",
    "    # debug.points = o3d.utility.Vector3dVector(pts_velo_cs_objects[:, :3])\n",
    "    # o3d.visualization.draw_geometries([debug])\n",
    "\n",
    "    assert (len(pts_velo_cs_objects) == len(objectness_objects))\n",
    "\n",
    "    if len(pts_velo_cs_objects) < 1:\n",
    "#         np.savez_compressed(os.path.join(write_dir, seq + '_' + str(idx).zfill(6)),\n",
    "#                             instances=[], segment_scores=[])\n",
    "        continue\n",
    "\n",
    "    # segmentation with point-net\n",
    "    id_ = 0\n",
    "    # eps_list = [2.0, 1.0, 0.5, 0.25]\n",
    "    eps_list_tum = [1.2488, 0.8136, 0.6952, 0.594, 0.4353, 0.3221]\n",
    "    indices, scores = segment(id_, eps_list_tum, pts_velo_cs_objects[:, :3])\n",
    "\n",
    "    # flatten list(list(...(indices))) into list(indices)\n",
    "    flat_indices = flatten_indices(indices)\n",
    "    # map from object_indexes to pts_indexes\n",
    "    mapped_indices = []\n",
    "    for indexes in flat_indices:\n",
    "        mapped_indices.append(pts_indexes_objects[indexes].tolist())\n",
    "\n",
    "    # mapped_flat_indices = pts_indexes_objects\n",
    "    flat_scores = flatten_scores(scores)\n",
    "\n",
    "    # visualizer\n",
    "    vis_instance_o3d()\n",
    "    break\n",
    "\n",
    "#     # save results\n",
    "#     np.savez_compressed(os.path.join(write_dir, seq + '_'+str(idx).zfill(6)),\n",
    "#                         instances=mapped_indices, segment_scores=flat_scores, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4071 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "seq = '08'\n",
    "# seq_prefix = '08_0'\n",
    "\n",
    "config_file = '/project_data/ramanan/achakrav/4D-PLS/data/SemanticKitti/semantic-kitti.yaml'\n",
    "\n",
    "task_set = 1\n",
    "# write_dir = '/project_data/ramanan/achakrav/hu-segmentation/kitti_raw_ts1_segmented/'\n",
    "write_dir = '/project_data/ramanan/achakrav/hu-segmentation/ts{}_trial/'.format(task_set)\n",
    "if not os.path.exists(write_dir):\n",
    "    os.makedirs(write_dir)\n",
    "\n",
    "# scan_folder = '/media/data/dataset/kitti-odometry/dataset/sequences/' + seq + '/velodyne'\n",
    "scan_folder = '/project_data/ramanan/achakrav/4D-PLS/data/SemanticKitti/sequences/' + seq + '/velodyne/'\n",
    "scan_files = load_paths(scan_folder)\n",
    "\n",
    "# objsem_folder = 'xieyuanlichen/tmp/seq08objsem'\n",
    "objsem_folder = '/project_data/ramanan/achakrav/4D-PLS/val_preds_TS{}/val_preds/'.format(task_set)\n",
    "objsem_files = load_paths(objsem_folder)\n",
    "\n",
    "label_folder = '/project_data/ramanan/achakrav/4D-PLS/data/SemanticKitti/sequences/' + seq + '/labels/'\n",
    "label_files = load_paths(label_folder)\n",
    "label_files = [x for x in label_files if '.label' in x]\n",
    "\n",
    "# for task set 1\n",
    "if task_set == 1:\n",
    "    class_strings = [\"car\", \"truck\", \"person\", \"road\", \"sidewalk\", \"building\", \"fence\", \"vegetation\", \"terrain\", \"pole\", \"unknown\"]\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "sem_file_mask = []\n",
    "obj_file_mask = []\n",
    "for idx, file in enumerate(objsem_files):\n",
    "    if '_c' in file:\n",
    "        obj_file_mask.append(idx)\n",
    "    elif '_c' not in file and '_i' not in file and '_e' not in file and '_pots' not in file:\n",
    "        sem_file_mask.append(idx)\n",
    "\n",
    "objectness_files = objsem_files[obj_file_mask]\n",
    "semantic_files = objsem_files[sem_file_mask]\n",
    "\n",
    "assert (len(semantic_files) == len(objectness_files))\n",
    "assert (len(semantic_files) == len(scan_files))\n",
    "\n",
    "learning_map = load_config(config_file, task_set)\n",
    "\n",
    "vis = JVisualizer()\n",
    "# vis.create_window()\n",
    "geometry = o3d.geometry.PointCloud()\n",
    "vis.add_geometry(geometry)\n",
    "\n",
    "\n",
    "for idx in tqdm(range(len(objectness_files))):\n",
    "    # load scan\n",
    "    scan_file = scan_files[idx]\n",
    "    pts_velo_cs = load_vertex(scan_file)\n",
    "    pts_indexes = np.arange(len(pts_velo_cs))\n",
    "\n",
    "    # load objectness\n",
    "    objectness_file = objectness_files[idx]\n",
    "    objectness = np.load(objectness_file)\n",
    "\n",
    "    # labels\n",
    "    label_file = semantic_files[idx]\n",
    "    labels = np.load(label_file)\n",
    "\n",
    "    unk_label = 11 # for task set 1\n",
    "\n",
    "    # ==========================================================================================\n",
    "    # Ani: plot predictions from 4DPLS \n",
    "    # ==========================================================================================\n",
    "    mask = labels != unk_label # Note: opposite to other plot since we plot known classes only\n",
    "    background_mask = labels == unk_label\n",
    "    \n",
    "    pts_velo_cs_objects = pts_velo_cs[mask]\n",
    "    objectness_objects = objectness[mask]\n",
    "    pts_indexes_objects = pts_indexes[mask]\n",
    "    labels_objects = labels[mask]\n",
    "    \n",
    "    # copied function from above\n",
    "    fg = o3d.geometry.PointCloud()\n",
    "    colors = np.zeros((len(pts_velo_cs_objects), 4))\n",
    "    max_cls = unk_label + 1 # [0, 11] for TS1\n",
    "    colors_cls = plt.get_cmap(\"tab20\")(np.arange(max_cls) / (max_cls if max_cls > 0 else 1))\n",
    "\n",
    "    colors = colors_cls[labels_objects]\n",
    "\n",
    "    # visualizer = JVisualizer()\n",
    "    visualizer = o3d.visualization.Visualizer()\n",
    "#     visualizer.create_window(visible=False)\n",
    "#     visualizer.get_render_option().point_color_option = o3d.visualization.PointColorOption.Color\n",
    "#     visualizer.get_render_option().point_size = 3.0\n",
    "    fg.points = o3d.utility.Vector3dVector(pts_velo_cs_objects[:, :3])\n",
    "    fg.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "    visualizer.add_geometry(fg)\n",
    "\n",
    "    bg = o3d.geometry.PointCloud()\n",
    "    bg.points = o3d.utility.Vector3dVector(pts_velo_cs[background_mask, :3])\n",
    "    bg.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "    visualizer.add_geometry(bg)\n",
    "    \n",
    "#     ctr = vis.get_view_control()\n",
    "    visualizer.capture_screen_image(\"file.jpg\", do_render=True)\n",
    "    visualizer.destroy_window()\n",
    "#     visualizer.show()\n",
    "    break\n",
    "\n",
    "    # visualize predictions\n",
    "#     vis_4dpls()\n",
    "#     break\n",
    "    # ==========================================================================================\n",
    "\n",
    "\n",
    "    # ==========================================================================================\n",
    "    # Ani: plot GT\n",
    "    # ==========================================================================================\n",
    "#     gt_label_file = label_files[idx]\n",
    "#     gt_label = np.fromfile(gt_label_file, dtype=np.int32)\n",
    "#     gt_label = gt_label & 0xFFFF\n",
    "#     gt_label = learning_map[gt_label]\n",
    "    \n",
    "#     # to plot clustering segmentation output\n",
    "#     mask = gt_label != unk_label\n",
    "#     background_mask = gt_label == unk_label\n",
    "\n",
    "#     pts_velo_cs_objects = pts_velo_cs[mask]\n",
    "#     objectness_objects = objectness[mask]\n",
    "#     pts_indexes_objects = pts_indexes[mask]\n",
    "#     labels_objects = gt_label[mask]\n",
    "    \n",
    "#     # visualize GT\n",
    "#     vis_4dpls()\n",
    "#     break\n",
    "    # ==========================================================================================\n",
    "\n",
    "    # debug = o3d.geometry.PointCloud()\n",
    "    # debug.points = o3d.utility.Vector3dVector(pts_velo_cs_objects[:, :3])\n",
    "    # o3d.visualization.draw_geometries([debug])\n",
    "\n",
    "#     assert (len(pts_velo_cs_objects) == len(objectness_objects))\n",
    "\n",
    "#     if len(pts_velo_cs_objects) < 1:\n",
    "# #         np.savez_compressed(os.path.join(write_dir, seq + '_' + str(idx).zfill(6)),\n",
    "# #                             instances=[], segment_scores=[])\n",
    "#         continue\n",
    "\n",
    "#     # segmentation with point-net\n",
    "#     id_ = 0\n",
    "#     # eps_list = [2.0, 1.0, 0.5, 0.25]\n",
    "#     eps_list_tum = [1.2488, 0.8136, 0.6952, 0.594, 0.4353, 0.3221]\n",
    "#     indices, scores = segment(id_, eps_list_tum, pts_velo_cs_objects[:, :3])\n",
    "\n",
    "#     # flatten list(list(...(indices))) into list(indices)\n",
    "#     flat_indices = flatten_indices(indices)\n",
    "#     # map from object_indexes to pts_indexes\n",
    "#     mapped_indices = []\n",
    "#     for indexes in flat_indices:\n",
    "#         mapped_indices.append(pts_indexes_objects[indexes].tolist())\n",
    "\n",
    "#     # mapped_flat_indices = pts_indexes_objects\n",
    "#     flat_scores = flatten_scores(scores)\n",
    "\n",
    "#     # visualizer\n",
    "#     vis_instance_o3d()\n",
    "#     break\n",
    "\n",
    "# #     # save results\n",
    "# #     np.savez_compressed(os.path.join(write_dir, seq + '_'+str(idx).zfill(6)),\n",
    "# #                         instances=mapped_indices, segment_scores=flat_scores, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
